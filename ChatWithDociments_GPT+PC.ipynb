{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.27.1\n",
      "  Downloading openai-0.27.1.tar.gz (57 kB)\n",
      "     ---------------------------------------- 57.3/57.3 kB 1.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: aiohttp in c:\\users\\28263\\anaconda3\\lib\\site-packages (from openai==0.27.1) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from openai==0.27.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\28263\\anaconda3\\lib\\site-packages (from openai==0.27.1) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.27.1) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.27.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.27.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.27.1) (2.2.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.27.1) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\28263\\anaconda3\\lib\\site-packages (from tqdm->openai==0.27.1) (0.4.6)\n",
      "Building wheels for collected packages: openai\n",
      "  Building wheel for openai (pyproject.toml): started\n",
      "  Building wheel for openai (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai: filename=openai-0.27.1-py3-none-any.whl size=70128 sha256=ff313a7101651b0e936160f31f643d7b9bd5a6e8916267ed6121b8416927d4c5\n",
      "  Stored in directory: c:\\users\\28263\\appdata\\local\\pip\\cache\\wheels\\41\\c8\\4f\\138501f9183f9d73c64387828c0a876edf0b330f8d1da3fca7\n",
      "Successfully built openai\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.8.0\n",
      "    Uninstalling openai-1.8.0:\n",
      "      Successfully uninstalled openai-1.8.0\n",
      "Successfully installed openai-0.27.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.0.2.post1 requires openai<2.0.0,>=1.6.1, but you have openai 0.27.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.184\n",
      "  Downloading langchain-0.0.184-py3-none-any.whl (939 kB)\n",
      "     -------------------------------------- 939.3/939.3 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (6.0)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (1.10.14)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (1.4.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (2.31.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (4.0.3)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (2.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (8.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (3.9.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (1.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from langchain==0.0.184) (0.5.14)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.184) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.184) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.184) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.184) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.184) (6.0.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.184) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.184) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain==0.0.184) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.184) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.184) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.184) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.184) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.184) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.184) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.184) (0.4.3)\n",
      "Installing collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.1\n",
      "    Uninstalling langchain-0.1.1:\n",
      "      Successfully uninstalled langchain-0.1.1\n",
      "Successfully installed langchain-0.0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langserve 0.0.39 requires langchain>=0.0.333, but you have langchain 0.0.184 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\28263\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from wikipedia) (4.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11707 sha256=00aed773b09e27594e0d549b6b1e8bc87986d89cafdaf824acfe78d0451e824e\n",
      "  Stored in directory: c:\\users\\28263\\appdata\\local\\pip\\cache\\wheels\\b2\\7f\\26\\524faff9145e274da278dc97d63ab0bfde1f791ecf101a9c95\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Requirement already satisfied: pypdf in c:\\users\\28263\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "     ---------------------------------------- 14.5/14.5 MB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\28263\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.23.5)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\28263\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (4.8.0)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==\n",
    "!pip install langchain==\n",
    "!pip install tiktoken\n",
    "!pip install wikipedia\n",
    "!pip install pypdf\n",
    "!pip install faiss-cpu\n",
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Training\n",
    "# LLM\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Document Loader\n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "\n",
    "# Tokenizer\n",
    "from transformers import GPT2TokenizerFast  \n",
    "\n",
    "# Embedding\n",
    "from langchain.embeddings import OpenAIEmbeddings \n",
    "\n",
    "# Vector DataBase\n",
    "from langchain.vectorstores import FAISS, Pinecone # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-based and permanent. \n",
    "\n",
    "# Chains\n",
    "#from langchain.chains.question_answering import load_qa_chain\n",
    "#from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pinecone_env_key = os.environ[\"PINECONE_ENV_KEY\"]\n",
    "\n",
    "# Alternatively, you can set the API keys as follows:\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "#PINECONE_API_KEY = \"34...\"\n",
    "#PINECONE_ENV_KEY = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "chatgpt = OpenAI(\n",
    "                 model_name = \"gpt-3.5-turbo-1160\", \n",
    "                 temperature= 0\n",
    ")\n",
    "\n",
    "prompt=\"Please, tell me some funny jokes\"\n",
    "\n",
    "print(chatgpt(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend the following destinations for your next trip:\n",
      "\n",
      "1. **Santorini, Greece**: Explore the stunning white-washed buildings perched on cliffs overlooking the crystal-clear waters of the Aegean Sea.\n",
      "   \n",
      "2. **Kyoto, Japan**: Immerse yourself in the rich history and culture of Kyoto by visiting ancient temples, traditional tea houses, and beautiful gardens.\n",
      "   \n",
      "3. **Banff National Park, Canada**: Experience the breathtaking beauty of the Canadian Rockies with turquoise lakes, snow-capped mountains, and abundant wildlife.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name = \"gpt-3.5-turbo\",\n",
    "                  temperature=0\n",
    "                 )\n",
    "\n",
    "high_level_behavior = \"\"\"\n",
    "                       You are an AI bot that help people decide where to travel. \n",
    "                       Always recommend three destination with a short sentence for each.\n",
    "                      \"\"\"\n",
    "\n",
    "response = chatgpt(\n",
    "    [\n",
    "        SystemMessage(content=high_level_behavior),\n",
    "        AIMessage(content=\"Hello! I am a traveller assistant, how can I help you?\"),\n",
    "        HumanMessage(content=\"Where should I travel next?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Based on your interest in museums, I recommend the following destinations:\n",
      "\n",
      "1. **Paris, France**: Explore world-renowned museums such as the Louvre, Musée d'Orsay, and Centre Pompidou in the artistic and cultural hub of Paris.\n",
      "\n",
      "2. **Florence, Italy**: Immerse yourself in the Renaissance art and history at museums like the Uffizi Gallery and Accademia Gallery, home to Michelangelo's David.\n",
      "\n",
      "3. **Mexico City, Mexico**: Discover the rich cultural heritage at museums like the National Museum of Anthropology and the Frida Kahlo Museum, showcasing the country's vibrant art and history.\n"
     ]
    }
   ],
   "source": [
    "response = chatgpt(\n",
    "        [\n",
    "            SystemMessage(content=high_level_behavior),\n",
    "            AIMessage(content=\"Hello! I am a traveller assistant, how can I help you?\"),\n",
    "            HumanMessage(content=\"Where should I travel next?\"),\n",
    "            SystemMessage(content=\"What do you enjoy doing?\"),\n",
    "            HumanMessage(content=\"I love going to Museums?\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your embedding is length 1536\n",
      "Here's a sample: [-0.0023176560644060373, -0.003950586076825857, -0.001200637430883944, -0.017430542036890984, -0.021305397152900696]...\n"
     ]
    }
   ],
   "source": [
    "# 1. Import the embedding model\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 2. Create an instance of the model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 3. Define a text to embed\n",
    "text = \"Hi! It's time to go to a Museum!\"\n",
    "\n",
    "# 4. Embed the text\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "\n",
    "\n",
    "conversation = ConversationChain(llm=chatgpt)\n",
    "conversation.run(\"Hello!\")\n",
    "\n",
    "#from langchain.chains.question_answering import load_qa_chain \n",
    "\n",
    "#chain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n",
    "#chain.run(input_documents = matches, question = enriched_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a memory via ConversationSummaryBufferMemory\n",
    "\n",
    "`ConversationSummaryBufferMemory` https://python.langchain.com/docs/modules/memory/types/summary_buffer,  It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both. It uses token length rather than number of interactions to determine when to flush interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Can you recommend me where should I travel next?\n",
      "AI: Hello! I am a traveller assistant, sure I can help you. What do you enjoy doing?\n",
      "Human: I love going to Museums\n",
      "AI: Great then you should go to a cultural capital.\n",
      "Human: What cities do you recommend me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Some popular cities known for their museums are Paris, London, New York City, and Tokyo. Each of these cities has a wide variety of museums to explore, ranging from art museums to history museums to science museums. If you're looking for a specific type of museum, let me know and I can provide more tailored recommendations!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=chatgpt, max_token_limit=100)\n",
    "\n",
    "memory.save_context({\"input\":  \"Can you recommend me where should I travel next?\"}, \n",
    "                    {\"output\": \"Hello! I am a traveller assistant, sure I can help you. What do you enjoy doing?\"})\n",
    "\n",
    "memory.save_context({\"input\":  \"I love going to Museums\"}, \n",
    "                    {\"output\": \"Great then you should go to a cultural capital.\"})\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name = \"gpt-3.5-turbo\",\n",
    "                  temperature=0\n",
    "                 )\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chatgpt, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.run(\"What cities do you recommend me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Let's imagine this is a huge document with a lot of words and important stuff.\", metadata={'document_id': 0, 'document_source': 'my_source', 'document_create_time': '01/01/2000'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import the document class\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 2. Define the document:\n",
    "Document(page_content=\"Let's imagine this is a huge document with a lot of words and important stuff.\",\n",
    "         metadata={\n",
    "             'document_id' : 0000,\n",
    "             'document_source' : \"my_source\",\n",
    "             'document_create_time' : \"01/01/2000\"\n",
    "         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Machine Learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field\\'s methods.\\nThe mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\\n\\n\\n== History ==\\n\\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb\\'s model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.By the early 1960s an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson\\'s book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing\\'s proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".Modern-day machine learning has two objectives.  One is to ', metadata={'title': 'Machine learning', 'summary': \"Machine Learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\\nThe mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Machine_learning'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    " \n",
    "# Load content from Wikipedia using WikipediaLoader\n",
    "loader = WikipediaLoader(\"Machine_learning\")\n",
    "wikipedia_data = loader.load() #It returns a list of documents\n",
    "\n",
    "wikipedia_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Content:  Machine Learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\n",
      "The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\n",
      "\n",
      "\n",
      "== History ==\n",
      "\n",
      "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.By the early 1960s an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".Modern-day machine learning has two objectives.  One is to \n",
      "\n",
      "Meta Data:  {'title': 'Machine learning', 'summary': \"Machine Learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\\nThe mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Machine_learning'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPage Content: \", wikipedia_data[0].page_content)\n",
    "print(\"\\nMeta Data: \", wikipedia_data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Loader\n",
    "from langchain.document_loaders import HNLoader\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")\n",
    "hn_data = loader.load()\n",
    "\n",
    "# Load content from local PDFs\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "loader = PyPDFLoader(\"attentions.pdf\")\n",
    "pdf_data = loader.load()\n",
    "\n",
    "#We can use a directory loader to load more than one PDF at once. \n",
    "#loader = PyPDFDirectoryLoader(\"Docs/\")\n",
    "#pdf_directory_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Wikipedia file with tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPLITTING BY CHUNKS\n",
      "Wikipedia Data - Now you have 73 number of chunks.\n"
     ]
    }
   ],
   "source": [
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "# Tokenizer\n",
    "from transformers import GPT2TokenizerFast  \n",
    "\n",
    "# Advanced method - Split by chunks ________________________________________________________________________\n",
    "# Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size      = 200, \n",
    "    chunk_overlap   = 20,\n",
    "    length_function = count_tokens # It uses len() by default. \n",
    ")\n",
    "\n",
    "print(\"\\nSPLITTING BY CHUNKS\")\n",
    "wikipedia_chunks = text_splitter.split_documents(wikipedia_data)\n",
    "print(\"Wikipedia Data - Now you have {0} number of chunks.\".format(len(wikipedia_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HN Data - Now you have 15 number of chunks.\n",
      "Local PDF - Now you have 232 number of chunks.\n"
     ]
    }
   ],
   "source": [
    "#_____________________________________________________________________PDF DATA\n",
    "# 1 - Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "# 2 - Tokenizer\n",
    "from transformers import GPT2TokenizerFast  \n",
    "\n",
    "# 3 - Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# 4 - Define the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size      = 200, \n",
    "    chunk_overlap   = 20,\n",
    "    length_function = count_tokens # It uses len() by default. \n",
    ")\n",
    "\n",
    "# 5 - Apply the .split_document command\n",
    "docs = text_splitter.split_documents(pdf_data)\n",
    "print(\"HN Data - Now you have {0} number of chunks.\".format(len(pdf_data)))\n",
    "\n",
    "\n",
    "#_____________________________________________________________________HN DATA\n",
    "# 1 - Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "# 2 - Tokenizer\n",
    "from transformers import GPT2TokenizerFast  \n",
    "\n",
    "# 3 - We use the default len, no need to do anything.\n",
    "\n",
    "# 4 - Define the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size      = 200, \n",
    "    chunk_overlap   = 20\n",
    ")\n",
    "\n",
    "\n",
    "hn_chunks = text_splitter.split_documents(hn_data)\n",
    "print(\"Local PDF - Now you have {0} number of chunks.\".format(len(hn_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure that the chunking has been successful by visualizing the distribution of chunk sizes. \n",
    "Since we have selected a chunk size of 200, the majority of our chunks should have this lenght:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\28263\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick data visualization to ensure chunking was successful\n",
    "\n",
    "# Create a list of token counts\n",
    "token_counts = [count_tokens(chunk.page_content) for chunk in docs]\n",
    "\n",
    "# Create a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Create a histogram of the token count distribution\n",
    "df.hist(bins=66, )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Split by pages**: If your data comes from documents organized in pages, there are methods that allow you to split data in pages to keep track of the page content. This method is specially useful when dealing with PDFs, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPLITTING BY PAGES\n",
      "PDF Splited by Pages - You have 16 number of chunks.\n"
     ]
    }
   ],
   "source": [
    "# Simple method - Split by pages    ________________________________________________________________________\n",
    "# You need a PDF file in your environement. \n",
    "loader = PyPDFLoader(r\"C:\\Users\\28263\\Downloads\\Docs\\attentions.pdf\")\n",
    "pdf_pages_chunks = loader.load_and_split()\n",
    "pdf_pages_chunks\n",
    "\n",
    "print(\"\\nSPLITTING BY PAGES\")\n",
    "print(\"PDF Splited by Pages - You have {0} number of chunks.\".format(len(pdf_pages_chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS - LOCAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS  # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# OPTION 1: FAISS (Facebook AI Similarity Search) Local _______________________________________________________________________________________\n",
    "# Create vector database\n",
    "db_FAISS = FAISS.from_documents(docs, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\28263\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (4.8.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client==3.0.0\n",
      "  Downloading pinecone_client-3.0.0-py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.9/199.9 kB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client==3.0.0) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client==3.0.0) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client==3.0.0) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\28263\\anaconda3\\lib\\site-packages (from pinecone-client==3.0.0) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\28263\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client==3.0.0) (0.4.6)\n",
      "Installing collected packages: pinecone-client\n",
      "  Attempting uninstall: pinecone-client\n",
      "    Found existing installation: pinecone-client 2.2.4\n",
      "    Uninstalling pinecone-client-2.2.4:\n",
      "      Successfully uninstalled pinecone-client-2.2.4\n",
      "Successfully installed pinecone-client-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
    "# OPTION 2: PINECONE Online\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "\n",
    "#from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "use_serverless = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# res = client.embeddings.create(\n",
    "#     input=[\n",
    "#         \"Sample document text goes here\",\n",
    "#         \"there will be several phrases in each batch\"\n",
    "#     ], model=MODEL\n",
    "# )\n",
    "\n",
    "# # we can extract embeddings to a list\n",
    "# embeds = [record.embedding for record in res.data]\n",
    "# len(embeds)\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "index_name = 'chatpdf' \n",
    "\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "if use_serverless:\n",
    "    spec = ServerlessSpec(cloud='aws', region='us-west-2')\n",
    "else:\n",
    "    # if not using a starter index, you should specify a pod_type too\n",
    "    spec = PodSpec(pod_type='starter', environment='gcp-starter')\n",
    "\n",
    "# check for and delete index if already exists\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# create a new index\n",
    "pc.create_index(\n",
    "    index_name,\n",
    "    dimension=1536,  # dimensionality of text-embedding-ada-002\n",
    "    metric='cosine',\n",
    "    spec=spec\n",
    ")\n",
    "\n",
    "# wait for index to be initialized\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "#Target the index and check its current stats:\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = '6e088a7e-2194-4ec3-9bd7-3f94ec4a9765'\n",
    "\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [ 21] and conditional\n",
      "computation [ 32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
      "[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n"
     ]
    }
   ],
   "source": [
    "query = \"What are transformers \"\n",
    "search = docsearch.similarity_search(query)\n",
    "print(search[0].page_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is transformer',\n",
       " 'result': 'The Transformer is a neural network architecture that is based entirely on attention mechanisms, dispensing with recurrence and convolutions. It is used for sequence transduction tasks, such as machine translation. The Transformer model allows for more parallelization, faster training times, and has shown superior performance compared to models based on recurrent or convolutional layers.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "query = 'What is transformer'\n",
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#With sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is transformer',\n",
       " 'answer': 'A transformer is a network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. It is used for sequence transduction models and has shown superior quality in machine translation tasks.\\n',\n",
       " 'sources': 'C:\\\\Users\\\\28263\\\\Downloads\\\\Docs\\\\attentions.pdf'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "qa_with_sources(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Clean up\n",
    "When you no longer need the index, use the delete_index operation to delete it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now upsert the data to Pinecone:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\28263\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "PDF Data - Now you have 15 number of chunks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "loader = PyPDFLoader(r\"C:\\Users\\28263\\Downloads\\Docs\\attentions.pdf\")\n",
    "pdf_data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "# 2 - Tokenizer\n",
    "from transformers import GPT2TokenizerFast  \n",
    "\n",
    "# 3 - Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# 4 - Define the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size      = 200, \n",
    "    chunk_overlap   = 20,\n",
    "    length_function = count_tokens # It uses len() by default. \n",
    ")\n",
    "\n",
    "# 5 - Apply the .split_document command\n",
    "docs = text_splitter.split_documents(pdf_data)\n",
    "print(\"PDF Data - Now you have {0} number of chunks.\".format(len(pdf_data)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a list of token counts\n",
    "token_counts = [count_tokens(chunk.page_content) for chunk in docs]\n",
    "\n",
    "# Create a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Create a histogram of the token count distribution\n",
    "df.hist(bins=66, )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeConfigurationError",
     "evalue": "You haven't specified an Api-Key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m pinecone_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6e088a7e-2194-4ec3-9bd7-3f94ec4a9765\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m pc \u001b[38;5;241m=\u001b[39m Pinecone(pinecone_api_key)  \n\u001b[1;32m----> 5\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeVectorStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\vectorstores.py:528\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    527\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_pinecone\\vectorstores.py:435\u001b[0m, in \u001b[0;36mPineconeVectorStore.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PineconeVectorStore:\n\u001b[0;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct Pinecone wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m     pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pinecone_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     pinecone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    438\u001b[0m     pinecone\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[0;32m    439\u001b[0m         texts,\n\u001b[0;32m    440\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(upsert_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    446\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_pinecone\\vectorstores.py:373\u001b[0m, in \u001b[0;36mPineconeVectorStore.get_pinecone_index\u001b[1;34m(cls, index_name, pool_threads, pinecone_api_key)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a Pinecone Index instance.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    Pinecone Index instance.\"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m _pinecone_api_key \u001b[38;5;241m=\u001b[39m pinecone_api_key \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 373\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_pinecone_api_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m indexes \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mlist_indexes()\n\u001b[0;32m    375\u001b[0m index_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indexes\u001b[38;5;241m.\u001b[39mindex_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\pinecone\\control\\pinecone.py:95\u001b[0m, in \u001b[0;36mPinecone.__init__\u001b[1;34m(self, api_key, host, config, additional_headers, pool_threads, index_api, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m configKwarg\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m PineconeConfig\u001b[38;5;241m.\u001b[39mbuild(api_key\u001b[38;5;241m=\u001b[39mapi_key, host\u001b[38;5;241m=\u001b[39mhost, additional_headers\u001b[38;5;241m=\u001b[39madditional_headers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_api:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_api \u001b[38;5;241m=\u001b[39m index_api\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\pinecone\\config\\pinecone_config.py:12\u001b[0m, in \u001b[0;36mPineconeConfig.build\u001b[1;34m(api_key, host, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, host: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, additional_headers: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m {},  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Config:\n\u001b[0;32m     11\u001b[0m     host \u001b[38;5;241m=\u001b[39m host \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_CONTROLLER_HOST\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_CONTROLLER_HOST\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ConfigBuilder\u001b[38;5;241m.\u001b[39mbuild(api_key\u001b[38;5;241m=\u001b[39mapi_key, host\u001b[38;5;241m=\u001b[39mhost, additional_headers\u001b[38;5;241m=\u001b[39madditional_headers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\pinecone\\config\\config.py:45\u001b[0m, in \u001b[0;36mConfigBuilder.build\u001b[1;34m(api_key, host, openapi_config, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m host \u001b[38;5;241m=\u001b[39m normalize_host(host)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified an Api-Key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified a host.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m: You haven't specified an Api-Key."
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pinecone_api_key = '6e088a7e-2194-4ec3-9bd7-3f94ec4a9765'\n",
    "pc = Pinecone(pinecone_api_key)  \n",
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index, embeddings, text_field = \"text\"\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
